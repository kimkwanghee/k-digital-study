{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#라이브러리 생성\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터 가져오기\n",
    "fashion_mnist=keras.datasets.fashion_mnist\n",
    "(train_images,train_labels),(test_images,test_labels)=fashion_mnist.load_data()\n",
    "\n",
    "# 모델 구성\n",
    "def create_model():\n",
    "    model=keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(28,28)),\n",
    "        keras.layers.Dense(128,activation='relu'),\n",
    "        keras.layers.Dense(10,activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
    "    return model\n",
    "model=create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 16s 7ms/step - loss: 8.9469 - sparse_categorical_accuracy: 0.6706 - val_loss: 0.8471 - val_sparse_categorical_accuracy: 0.7384\n",
      "\n",
      "Epoch 00001: saving model to traiinig_1\\cp.ckpt\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.7320 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.6780 - val_sparse_categorical_accuracy: 0.7503\n",
      "\n",
      "Epoch 00002: saving model to traiinig_1\\cp.ckpt\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5788 - sparse_categorical_accuracy: 0.7899 - val_loss: 0.5752 - val_sparse_categorical_accuracy: 0.8233\n",
      "\n",
      "Epoch 00003: saving model to traiinig_1\\cp.ckpt\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.5296 - sparse_categorical_accuracy: 0.8183 - val_loss: 0.5652 - val_sparse_categorical_accuracy: 0.7936\n",
      "\n",
      "Epoch 00004: saving model to traiinig_1\\cp.ckpt\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4995 - sparse_categorical_accuracy: 0.8269 - val_loss: 0.5638 - val_sparse_categorical_accuracy: 0.8044\n",
      "\n",
      "Epoch 00005: saving model to traiinig_1\\cp.ckpt\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4933 - sparse_categorical_accuracy: 0.8324 - val_loss: 0.5515 - val_sparse_categorical_accuracy: 0.8301\n",
      "\n",
      "Epoch 00006: saving model to traiinig_1\\cp.ckpt\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4821 - sparse_categorical_accuracy: 0.8357 - val_loss: 0.5617 - val_sparse_categorical_accuracy: 0.8226\n",
      "\n",
      "Epoch 00007: saving model to traiinig_1\\cp.ckpt\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.4862 - sparse_categorical_accuracy: 0.8364 - val_loss: 0.5052 - val_sparse_categorical_accuracy: 0.8249\n",
      "\n",
      "Epoch 00008: saving model to traiinig_1\\cp.ckpt\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.4646 - sparse_categorical_accuracy: 0.8419 - val_loss: 0.5568 - val_sparse_categorical_accuracy: 0.8239\n",
      "\n",
      "Epoch 00009: saving model to traiinig_1\\cp.ckpt\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4652 - sparse_categorical_accuracy: 0.8431 - val_loss: 0.5289 - val_sparse_categorical_accuracy: 0.8355\n",
      "\n",
      "Epoch 00010: saving model to traiinig_1\\cp.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29a115e3790>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path='traiinig_1/cp.ckpt'\n",
    "checkpoint_dir=os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback=tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1)\n",
    "\n",
    "model.fit(train_images,train_labels,epochs=10,\n",
    "         validation_data=(test_images,test_labels),\n",
    "         callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.새로운 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 173.2805 - sparse_categorical_accuracy: 0.1324\n",
      "정확도:13.24%\n"
     ]
    }
   ],
   "source": [
    "model=create_model()\n",
    "\n",
    "loss, acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('정확도:{:5.2f}%'.format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 저장된 모델 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.5289 - sparse_categorical_accuracy: 0.8355\n"
     ]
    }
   ],
   "source": [
    "# 가중치 로드\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "# 모델 재평가\n",
    "loss, acc = model.evaluate(test_images, \n",
    "                           test_labels, \n",
    "                           verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 체크포인트 콜백 매개변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: saving model to traiinig_1\\cp-0001.ckpt\n",
      "\n",
      "Epoch 00002: saving model to traiinig_1\\cp-0002.ckpt\n",
      "\n",
      "Epoch 00003: saving model to traiinig_1\\cp-0003.ckpt\n",
      "\n",
      "Epoch 00004: saving model to traiinig_1\\cp-0004.ckpt\n",
      "\n",
      "Epoch 00005: saving model to traiinig_1\\cp-0005.ckpt\n",
      "\n",
      "Epoch 00006: saving model to traiinig_1\\cp-0006.ckpt\n",
      "\n",
      "Epoch 00007: saving model to traiinig_1\\cp-0007.ckpt\n",
      "\n",
      "Epoch 00008: saving model to traiinig_1\\cp-0008.ckpt\n",
      "\n",
      "Epoch 00009: saving model to traiinig_1\\cp-0009.ckpt\n",
      "\n",
      "Epoch 00010: saving model to traiinig_1\\cp-0010.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29a1d7acc70>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#warning 메시지 숨기기\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "\n",
    "# 파일이름에 에포크 번호 포함\n",
    "checkpoint_path='traiinig_1/cp-{epoch:04d}.ckpt'\n",
    "checkpoint_dir=os.path.dirname(checkpoint_path)\n",
    "#e다섯번째 에포크 마다 저장(저장주기설정)\n",
    "cp_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    verbose=1,\n",
    "    save_freq='epoch')\n",
    "\n",
    "#새로운 모델 객체\n",
    "model=create_model()\n",
    "\n",
    "#checkpoint_path 가중치 저장\n",
    "model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "#새로운 콜벡 사용하여 모델 훈련\n",
    "model.fit(train_images,\n",
    "          train_labels,\n",
    "          epochs=10,\n",
    "         validation_data=(test_images,test_labels),\n",
    "         callbacks=[cp_callback],\n",
    "         verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'traiinig_1\\\\cp-0010.ckpt'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest=tf.train.latest_checkpoint(checkpoint_dir)\n",
    "latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 최종 체크포인트로 모델 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.5661 - sparse_categorical_accuracy: 0.8192\n",
      "복원된 모델의 정확도: 81.92%\n"
     ]
    }
   ],
   "source": [
    "#warning 메시지 숨기기\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "#새로운 모델 객체를 만듬\n",
    "model=create_model()\n",
    "\n",
    "#이전에 저장한 가중치 로드\n",
    "model.load_weights(latest)\n",
    "\n",
    "#모델 재평가\n",
    "loss, acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print(\"복원된 모델의 정확도: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 현재 모델 weights 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.5661 - sparse_categorical_accuracy: 0.8192\n",
      "복원된 모델의 정확도: 81.92%\n"
     ]
    }
   ],
   "source": [
    "# 가중치를 저장합니다\n",
    "model.save_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "# 새로운 모델 객체를 만듭니다\n",
    "model1 = create_model()\n",
    "\n",
    "# 가중치를 복원합니다\n",
    "model1.load_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "# 모델을 평가합니다\n",
    "loss,acc = model1.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(\"복원된 모델의 정확도: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 모델 전체 저장(savemodel)\n",
    "- 전체 모델을 파일 하나에 저장하는 방법 제공 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "1875/1875 [==============================] - 9s 4ms/step - loss: 9.5654 - sparse_categorical_accuracy: 0.6766 - val_loss: 0.7687 - val_sparse_categorical_accuracy: 0.7068\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6504 - sparse_categorical_accuracy: 0.7690 - val_loss: 0.6443 - val_sparse_categorical_accuracy: 0.7717\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5778 - sparse_categorical_accuracy: 0.7939 - val_loss: 0.6360 - val_sparse_categorical_accuracy: 0.7700\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5489 - sparse_categorical_accuracy: 0.8059 - val_loss: 0.5984 - val_sparse_categorical_accuracy: 0.7887\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.5185 - sparse_categorical_accuracy: 0.8169 - val_loss: 0.5620 - val_sparse_categorical_accuracy: 0.8103\n",
      "INFO:tensorflow:Assets written to: ./saved_model/my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# # 새로운 모델 객체를 만들고 훈련합니다\n",
    "model = create_model()\n",
    "model.fit(train_images, train_labels, epochs=5,validation_data = (test_images, test_labels))\n",
    "\n",
    "# # SavedModel로 전체 모델을 저장합니다\n",
    "#!mkdir -p saved_model \n",
    "# model.save('./traiining_1/my_model')\n",
    "\n",
    "path='./saved_model/my_model'\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "if os.path.isdir(path):\n",
    "    shutil.rmtree(path)\n",
    "\n",
    "os.makedirs(path)\n",
    "\n",
    "model.save(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 모델 전체를 load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_18 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model=tf.keras.models.load_model(path)\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 모델적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.5620 - sparse_categorical_accuracy: 0.8103\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss, acc = new_model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(new_model.predict(test_images).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 모델 전체 저장(hdf5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 8.2690 - sparse_categorical_accuracy: 0.6768\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7252 - sparse_categorical_accuracy: 0.7116\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5830 - sparse_categorical_accuracy: 0.7842\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5288 - sparse_categorical_accuracy: 0.8117\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5058 - sparse_categorical_accuracy: 0.8233\n",
      "313/313 - 1s - loss: 0.5697 - sparse_categorical_accuracy: 0.8175\n"
     ]
    }
   ],
   "source": [
    "# 새로운 모델 객체를 만들고 훈련합니다\n",
    "model = create_model()\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "loss, acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "# 전체 모델을 HDF5 파일로 저장합니다\n",
    "# '.h5' 확장자는 이 모델이 HDF5로 저장되었다는 것을 나타냅니다\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_20 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 가중치와 옵티마이저를 포함하여 정확히 동일한 모델을 다시 생성합니다\n",
    "new_model = tf.keras.models.load_model('my_model.h5')\n",
    "\n",
    "# 모델 구조를 출력합니다\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.5697 - sparse_categorical_accuracy: 0.8175\n",
      "복원된 모델의 정확도: 81.75%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = new_model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('복원된 모델의 정확도: {:5.2f}%'.format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
